\begin{center}
	\zihao{3}{ \heiti Explainable Judicial Outcome Prediction: A Legal Provision-Constrained and Case-Based Fusion Framework}\\
	% \vspace {5mm}
	% \zihao{5}{ Dingwen Zhang$^{1,\dagger}$\quad Zhentao Liang$^{1,\dagger}$\quad Yili Zhu$^{1}$\quad Hua Zhang$^{1}$\quad Yongbin Qin$^{1,2,3}$\quad  Ruizhang Huang$^{1,2,3}$}

    % \vspace {1mm}

	% \zihao{6}{{$^{1}$Department of Computer and Science, Guizhou University, Guiyang, 550004}}

	% \zihao{6}{{$^{2}$State Key Laboratory of Public Big Data (Guizhou University), Guiyang, 550004}}

	% \zihao{6}{{$^{3}$Text Computing \& Cognitive Intelligence Engineering Research Center of National Education Ministry, Guizhou University, Guiyang, 550004}}
\end{center}

\zihao{5}{
	{\noindent\bf Abstract}\quad
	%英文摘要
	\zihao{5}{\noindent
	Legal judgment prediction is a critical research area driving judicial intelligence. However, current Large Language Models (LLMs) face significant challenges in this task. Without specialized legal knowledge enhancement, LLMs primarily rely on their inherent knowledge for reasoning, which often leads to "hallucinations"—generating judgments inconsistent with legal facts or logic—when handling complex legal cases. Furthermore, LLMs' insufficient deep understanding and precise application of professional legal knowledge severely limit their reliability and interpretability in judicial practice. Legal judgment prediction is a critical research area driving judicial intelligence. However, current Large Language Models (LLMs) face significant challenges in this task. Without specialized legal knowledge enhancement, LLMs primarily rely on their inherent knowledge for reasoning, which often leads to "hallucinations"—generating judgments inconsistent with legal facts or logic—when handling complex legal cases. Furthermore, LLMs' insufficient deep understanding and precise application of professional legal knowledge severely limit their reliability and interpretability in judicial practice. This study aims to systematically improve judgment quality by providing LLMs with clear legal grounds and practical judicial references. Experimental results demonstrate that this method achieved F1 scores of 0.7743 and 0.5525 on the charge prediction and sentence prediction tasks, respectively. Compared to advanced baseline models that also attempted to integrate external knowledge bases, its F1 scores improved by 2.46\% and 8.34\%, respectively. This fully validates that our method, through the effective fusion of multi-source heterogeneous knowledge, can significantly enhance the accuracy of judgment prediction.
	}}

\vspace {5mm}

\zihao{5-}{\noindent
	{\heiti Key words\quad}{Large Language Models; Retrieval-Augmention Generation; Judgment Prediction; Smart Courts;}
}\par\noindent

\zihao{5}
\vskip 1mm